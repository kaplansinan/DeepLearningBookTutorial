{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Probability for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability plays a key role in moder machine learning application as it is all about modeling and making predictions. For instance;\n",
    "* making predictions about the probability of a patient having certain eye related disease(glaucoma etc) in the next year, given person's medical history\n",
    "* detecting anomalies and spams\n",
    "* structuring reward and punishment mechanisms in reinforcement learning while an agent performs certain tasks\n",
    "* in recommendation engines, we can predict the probability of a user who might buy a particular product ato recommend related products alongside with it. \n",
    "\n",
    "To be able to understand above mentioned use cases clearly, first we need to have a vivid understanding of ```probability and information theory ```.\n",
    "\n",
    "While ***probability theory*** is a fundamental mathematical framework to represent uncertainty, ***information theory*** is a way to measure the amount uncertainty quantitatively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Why to study probaility\n",
    "In Machine Learning applications we deal with uncertain and stochastic (nondetemrnisitic) quantities. These uncertainties mainly come from many sources. Such as:\n",
    "\n",
    "* ```Incomplete observability```: When making predictions about certain events in applications we mostly dont have all observations from the event happening. \n",
    " \n",
    "``` \n",
    "[TODO]\n",
    "* add example\n",
    "```\n",
    "\n",
    "* ```Incomplete modeling```: While building machine learning models it is not always possible to include all information observed into model. As a result, the model has uncertainty in its predictions. \n",
    "\n",
    "``` \n",
    "[TODO]\n",
    "* add example\n",
    "```\n",
    "\n",
    "Another scenario in which we need to apply probability is that in certains cases it is more useful to use a simple probabilistic rule rather than modeling a deterministic complex rule. \n",
    "\n",
    "\n",
    "``` \n",
    "[TODO]\n",
    "* add example\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Random Variable\n",
    "We will be using random variables a lot throughout this notebook as they are descriptions of states that are possible. \n",
    "\n",
    "We will donate random variable with $\\mathbr{x} = x$and it s possoible values $x_1, x_2,...,x_n$.\n",
    "\n",
    "Random variable may have discrete or continous values. While discrete random variables have a finite or countably imfinite number of states, continuous random variables have real values. \n",
    "\n",
    "https://www.math.ubc.ca/~pwalls/math-python/jupyter/latex/\n",
    "\n",
    "https://en.wikibooks.org/wiki/LaTeX/Mathematics\n",
    "\n",
    "https://towardsdatascience.com/probability-and-statistics-explained-in-the-context-of-deep-learning-ed1509b2eb3f\n",
    "\n",
    "https://machinelearningmastery.com/why-learn-probability-for-machine-learning/\n",
    "\n",
    "https://www.math.ubc.ca/~pwalls/math-python/jupyter/latex/\n",
    "\n",
    "https://d2l.ai/chapter_preliminaries/probability.html#independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Probability Distributions\n",
    "A probability distribution is a mathematical function that describes all the possible values and likelihoods that a random variable or a set of random variable can take. It is defined based on whether the variables are discrete or continous.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Discrete Variables and Probability Mass Functions\n",
    "\n",
    "$\\forall x \\in X, \\quad \\exists y \\leq \\epsilon$ \n",
    "\n",
    "We usually define a probability distirbution over  discrete variables by a ***probability mass function (PMF)*** and denoted by capital ***P***. \n",
    "\n",
    "PMF maps from a state of a random variable to the probability of that random variable taking on that state. In mathematical terms we define that as  follows: \n",
    "$\\mathrm{x} = x$ is $P(x)$\n",
    "\n",
    "While defining a ***joint probability*** over many variables at the same time, we use the notation as $P(\\mathrm{x} = x,\\mathrm{y} = y)$ and it denotes the probaility $\\mathrm{x} = x$ and $\\mathrm{y} = y$ simultaneously. It can be also written by only $P(x, y)$. \n",
    "\n",
    "There is certain conditions that $P$ must satisfy in order to be PMF on a random variable:\n",
    "* $\\forall x \\in \\mathrm{x}, 0 \\leq P(x) \\leq 1$. In other words, the probabilty must be between 0 and 1.\n",
    "* $\\sum_{x \\in \\mathrm{x}} P(x) = 1$. That is a ***normalization*** term in probability and it indicates an important property. That allows us not to obtain probabilities greater than 1. \n",
    "\n",
    "#### Sample 1: Discrete Uniform distribution\n",
    "To demosntrate this by plotting uniform distribution. The ***uniform distribution*** makes each states equally likely.\n",
    "\n",
    "[TODO]\n",
    "https://docs.scipy.org/doc/scipy/reference/tutorial/stats/discrete_randint.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5e51b1bbad8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "array = [1,2,3,4,5]\n",
    "plt.plot(array)\n",
    "plt.show()\n",
    "# \\mathrm{x}\n",
    "#https://plot.ly/python/getting-started/#initialization-for-offline-plotting\n",
    "#https://realpython.com/python-histograms/\n",
    "#https://jakevdp.github.io/PythonDataScienceHandbook/04.09-text-and-annotation.html\n",
    "#https://matplotlib.org/3.1.1/gallery/text_labels_and_annotations/usetex_demo.html#sphx-glr-gallery-text-labels-and-annotations-usetex-demo-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Continuous Variables and Probability Density Functions\n",
    "\n",
    "When we work with continuos variables we use ***probability density functions (PDF)*** instead of PMF. We denote pdf as $p$. \n",
    "PDF must satisfy following conditions:\n",
    "* $\\forall x \\in \\mathrm{x}, p(x) \\geq 0$\n",
    "* $\\int p(x) dx = 1$\n",
    "\n",
    "#### Sample 2: Continuos Uniform Distribution\n",
    "We can define uniform distribution for continuos variable as a function of $u(x;a,b)$, where $a$ and $b$ are the end points of the interval with $b \\gt a$. This whole notation equals to:\n",
    "$$\n",
    "u(x;a,b) = \\frac{1}{b-a}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Marginal Probability\n",
    "\n",
    "Marginalization is the operation of determining  $P(y)$  from  $P(x,y)$.\n",
    "\n",
    "$$\n",
    "P(y) = \\sum_{x}P(x,y)\n",
    "$$\n",
    " \n",
    "This is also known as the **sum rule**. The probability or distribution as a result of marginalization is called a marginal probability or a marginal distribution. It is an answer of folloing question:\n",
    " * what is the probability of a subset of random variables from a superset of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Conditional Probability\n",
    "\n",
    "In many machine learning problems,  conditional probability gives the probability of some event, given some other event occured. We denote that as $\\mathrm{y} = y$ given $\\mathrm{x} = x$ by $P(\\mathrm{y} = y  \n",
    "|  \\mathrm{x} = x)$. This can be formulated as follow:\n",
    "\n",
    "$$\n",
    "P(\\mathrm{y} = y  |  \\mathrm{x} = x) = \\frac{P(\\mathrm{y} = y,\\mathrm{x} = x)}{P(\\mathrm{x} = x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Independence and Conditional Indepedence\n",
    "\n",
    "It is also important to understand the difference between dependence and independence in probability. Two random variables  $\\mathrm{x}$ and  $\\mathrm{y}$ are independent means that the occurrence of one event of  $\\mathrm{x}$  does not reveal any information about the occurrence of an event of  $\\mathrm{y}$. \n",
    "\n",
    "In mathmetical terms:\n",
    "\n",
    "$$\n",
    "\\forall x \\in \\mathrm{x}, \\forall y \\in \\mathrm{y},P(\\mathrm{x} = x,\\mathrm{y} = y) =P(\\mathrm{x} = x)P(\\mathrm{y} = y) \n",
    "$$\n",
    "\n",
    "Another usefull property of probability is conditional independece. That means two random variables $x$ and $y$ conditionally independet given a random variable $z$. It can be factorized as follows: \n",
    "$$\n",
    "\\forall x \\in \\mathrm{x}, \\forall y \\in \\mathrm{y}, \\forall z \\in \\mathrm{z},P(\\mathrm{x} = x,\\mathrm{y} = y |\\mathrm{z} = z)   = P(\\mathrm{x} = x |\\mathrm{z} = z)P(\\mathrm{y} = y |\\mathrm{z} = z) \n",
    "$$\n",
    "\n",
    "The compact notations of independence and conditional independence are given below:\n",
    "* ```Independence```: $x \\perp y$\n",
    "* ```Conditional Independence```: $x \\perp y | z$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Expectation, Variance and Covarince\n",
    "**Expected value** of some function $f(x)$ w.r.t. a probability distribution $P( \\mathrm{x})$ is the mean value that $f$ takes when $x$ is drawn from P.\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "E_x = \\sum_{x}P(x)f(x)$$\n",
    "\n",
    "\n",
    "**Variance** is the measure of variability in the data from the mean value. In probability, it is the variability of $f$ from it's expected value drawn from it's probability distribution. \n",
    "$$\n",
    "Var(f(x)) = E[(f(x) -E[f(x)])^2]\n",
    "$$\n",
    "\n",
    "If the variance is low, $f(x)$ approximates close to mean value. \n",
    "\n",
    "**Covariance** is the measure of linear relationship between values. \n",
    "$$\n",
    "Cov(f(x),g(y)) = E[(f(x) -E[f(x)])(g(y) -E[g(y)])]\n",
    "$$\n",
    "\n",
    "\n",
    "Covariance matrix of a random variable $x \\in \\mathbb{R}^n $ is an $n \\times n$ matrix and its diagonal elements give the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Commonly used Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.1 Binomial distribution\n",
    "A binomial random variable is the number of successes in n trials of a random experiment. A random variable x is said to follow binomial distribution when, the random variable can have only two outcomes(success and failure).Naturally , binomial distribution is for discrete random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "n=10 # number of trials\n",
    "p=0.5 # probability of success\n",
    "s=1000 # size\n",
    "b_d = np.random.binomial(n,p,s)\n",
    "#https://www.datacamp.com/community/tutorials/probability-distributions-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_probability'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-41494c8c96ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_probability\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_probability'"
     ]
    }
   ],
   "source": [
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.2 Bernoulli Distribution\n",
    "A Bernoulli distribution has only two possible outcomes, namely 1 (success) and 0 (failure), and a single trial, for example, a coin toss. So the random variable $x$ which has a Bernoulli distribution can take value 1 with the probability of success, $p$, and the value 0 with the probability of failure, $q$ or $1−p$. The probabilities of success and failure need not be equally likely. The Bernoulli distribution is a special case of the binomial distribution where a single trial is conducted $(n=1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.3 Multinoulli Distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __multinoulli__ or __categorical distribution__ is a distribution over a single discrete variable with *k* different states, where *k* is finite. The multinoulli distribution is a special case of the __multinomial distribution__, which is a generalization of Binomial distribution. A multinomial distribution is the distribution over vectors in ${0, \\cdots, n}^k$ representing how many times each of the *k* categories visited when *n* samples are drawn from a multinoulli distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.3 Gaussian Distribution\n",
    "\n",
    "A normal distribution has a bell-shaped density curve described by its mean μ and standard deviation σ.  The probability distribution function of a normal density curve with mean μ and standard deviation σ at a given point x is given by:\n",
    "\n",
    "\n",
    "\n",
    "The most commonly used distribution over real numbers is the __normal distribution__, also known as the __Gaussian distribution__:\n",
    "\n",
    "$$\\color{green}{\\mathcal{N}(x; \\mu, \\sigma^2) = \\sqrt{\\frac{1}{2 \\pi \\sigma^2}} exp \\Big(- \\frac{1}{2 \\sigma^2} (x - \\mu)^2 \\Big) \\tag{15}}$$\n",
    "\n",
    "The two parameters $\\mu \\in \\mathbb{R}$ and $\\sigma \\in (0, \\infty)$ control the normal distribution. The parameter $\\mu$ gives the coordinate of the central peak. This is also the mean of the distribution: $\\mathbb{E}[\\mathrm{x}] = \\mu$. The standard deviation of the distribution is given by $\\sigma$, and the variance by $\\sigma^2$.\n",
    "\n",
    "The density curve is symmetrical, centered about its mean, with its spread determined by its standard deviation showing that data near the mean are more frequent in occurrence than data far from the mean.\n",
    "\n",
    "\n",
    "In the absence of prior knowledge about what form a distribution over the real numbers should take, the normal distribution is a good choice because, it has high entropy and central limit theorem suggests that sum of several independent random variables is normally distributed.\n",
    "\n",
    "\n",
    "The normal distribution generalizes to $\\mathbb{R}^n$, in which case it is known as the __multivariate normal distribution__. It may be parameterized with a positive definite symmetric matrix $\\Sigma$:\n",
    "\n",
    "$$\\color{green}{\\mathcal{N}(x; \\mu, \\Sigma) = \\sqrt{\\frac{1}{(2 \\pi)^n det(\\Sigma)}} exp \\Biggr(- \\frac{1}{2} (x - \\mu)^\\top \\Sigma^{(-1)} (x - \\mu) \\Biggr) \\tag{16}}$$\n",
    "\n",
    "The parameter $\\mu$ still gives the mean of the distribution, though now it is vector valued. The parameter $\\Sigma$ gives the covariance matrix of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Mixture of Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common way of combining simpler distributions to define probability distribution is to construct a __mixture distribution__. A mixture distribution is made up of several component distributions. On each trial, the choice of which component distribution should generate the sample is determined by sampling a component identity from a multinoulli distribution:\n",
    "\n",
    "$$\\color{orange}{P(\\mathrm{x}) = \\displaystyle\\sum_i P(c = i) \\ P(\\mathrm{x} | c = i) \\tag{21}}$$\n",
    "\n",
    "where $P(c)$ is the multinoulli distribution over component identities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mixture model allows us to briefly glimpse a concept that will be of paramount importance later—the __latent variable__. A latent variable is a random variable that we cannot observe directly. Latent variables may be related to x through the joint distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 - Bayes' Rule\n",
    "\n",
    "__Bayes' rule__ is a useful tool that computes the conditional probability $P( x | y)$ from $P(y | x)$. Here \n",
    "\n",
    "- $P( x | y)$ is called the _posterior_; what we are trying to estimate, \n",
    "- $P(y | x)$ is called the _likelihood_; the probability of observing the new evidence, given our initial hypothesis, \n",
    "- $P(x)$ is called the _prior_; this is the probability of our hypothesis without any additional prior information,\n",
    "- $P(y)$ is called the _marginal likelihood_; this is the total probability of observing the evidence.\n",
    "\n",
    "The Bayes' rule can be summed up as:\n",
    "\n",
    "$$\\color{orange}{P(x | y) = \\frac{P(x) \\ P(y | x)}{P(y)} \\tag{24}}$$\n",
    "\n",
    "Even though $P(y)$ appears in the formula, it is usually feasible to compute $P(y) = \\sum_x P(y | x) P(x)$, so we do not need to begin with knowledge of $P(y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10 - Information Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information theory is a branch of applied mathematics that revolves around quantifying how much information is present in a signal. In the context of machine learning, we can also apply information theory to continuous variables where some of these message length interpretations do not apply. \n",
    "\n",
    "The basic intuition behind the information theory is that a likely event should have low information content, less likely events should have higher information content and independent events should have additive information.\n",
    "\n",
    "\n",
    "To satisfy these properties, we define the __self-information__ of an event $\\mathrm{x} = x$ to be:\n",
    "\n",
    "$$\\color{orange}{I(x) = -log \\ P(x) \\tag{27}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self information deals only with a single outcome. We can quantify the amount of uncertainty in an entire probability distribution using the __Shannon entropy__:\n",
    "\n",
    "$$\\color{orange}{H(\\mathrm{x}) = \\mathbb{E}_{x \\sim P} [I(x)] = -\\mathbb{E}_{x \\sim P}[log \\ P(x)] \\tag{28}}$$\n",
    "\n",
    "also denoted as $H(P)$.\n",
    "\n",
    "Shannon entropy of a distribution is the expected amount of information in an event drawn from that distribution. It gives a lower bound on the number of bits needed on average to encode symbols drawn from a distribution P. Distributions that are nearly deterministic (where the outcome is nearly certain) have low entropy; distributions that are closer to uniform have high entropy. When $\\mathrm{x}$ is continuous, the Shannon entropy is known as the __differential entropy__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy isn't remarkable for its interpretation, but for its  properties. For example, entropy doesn't care about the actual *x* values like variance, it only considers their probability. So if we increase the number of values *x* may take then the entropy will increase and the probabilities will be less concentrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have two separate probability distributions P(x) and Q(x) over the same random variable x, we can measure how different these two distributions are using the __Kullback-Leibler (KL) divergence__:\n",
    "\n",
    "$$\\color{orange}{D_{KL} (P \\| Q) = \\mathbb{E}_{x \\sim P} \\Big[ log \\ \\frac{P(x)}{Q(x)} \\Big] = \\mathbb{E}_{x \\sim P} [log \\ P(x) - log \\ Q(x)] \\tag{29}}$$\n",
    "\n",
    "In the case of discrete variables, it is the extra amount of information needed to send a message containing symbols drawn from probability distribution P, when we use a code that was designed to minimize\n",
    "the length of messages drawn from probability distribution Q.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KL divergence has many useful properties, most notably being nonnegative. The KL divergence is 0 if and only if P and Q are the same distribution in the case of discrete variables, or equal “almost everywhere” in the case of continuous variables.\n",
    "\n",
    "A quantity that is closely related to the KL divergence is the __cross-entropy__ $H(P, Q) = H(P) + D_{KL} (P \\| Q)$, which is similar to the KL divergence but lacking the term on the left:\n",
    "\n",
    "$$\\color{orange}{H(P, Q) = - \\mathbb{E}_{x \\sim P} \\ log \\ Q(x) \\tag{30}}$$\n",
    "\n",
    "Minimizing the cross-entropy with respect to Q is equivalent to minimizing the KL divergence, because Q does not participate in the omitted term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Models\n",
    "Explain in Graph Neural Nets and Bayesian Nets section"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
