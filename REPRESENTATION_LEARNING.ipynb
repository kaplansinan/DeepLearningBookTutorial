{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTux5NpKv4cv"
   },
   "source": [
    "### REPRESENTATION LEARNING\n",
    "\n",
    "Representation learning is a way of learning representations of input data typically by transorming it or extracting features from it.\n",
    "In probabilistic scenario, the goal is to learn a representation that captures a probability distribution of underlying explanatory features for observed input. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mzjt_n9cv4cx"
   },
   "source": [
    "### Representation Learning and Knowledge Quality\n",
    "It deals with extracting understanding the characteristics of input data. It is equivalent to feature learning. Its relevance has increased tremendously lately with the emergence of deep learning. \n",
    "\n",
    "KEY QUESTIONS:\n",
    "* How do we determine an optimal representation of the input data?\n",
    "\n",
    "***Remember NO FREE LUNCH THEOREM***\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kP1WWkuvv4cy"
   },
   "source": [
    "### REGULARIZATION AS A TOOL TO LEARN REPRESENTATIONS\n",
    "\n",
    "The question we need to answer here is that how representation learning is related reqularization?\n",
    "\n",
    "* The quality of a knowledge representation is fundamentally related to its ability to generalize knowledge efficiently. In other words, the knowledge representatin must be able to adapt new inputs outside the training dataset. \n",
    "* In order to perform well with new inputs and reduce the genralization error, any representation knowledge should be useful in reqularization techniques. \n",
    "* Therefore, quality of representation learning model is directly influenced by its ability to work with different reqularization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K35qJ2_kv4cy"
   },
   "source": [
    "### IMPROVING KNOWLEDGE BY REGULARIZATION\n",
    "There are a few characteristics that make knowledge representations more efficient when comes to regularization. Five of them are:\n",
    "\n",
    "1. Disentangling of causal factors: Robust features are important factors to seperate some features from others.  This can be achieved by learning features corresponding to the underlying causes of the training data.  \n",
    "\n",
    "2. Smoothness: This is an assumption that a value of a hypothesis does not change drastically among points in close proximity in the input dataset. \n",
    "\n",
    "3. Linearity: This assumes that relationships between some input variables is linear. \n",
    "\n",
    "4. Hierarchical Structures: This assumes that there esxists a knowledge representation based on hierarchy. A hierarchy assumes that every step in the network can be explained by previous steps which tremendously help to better reason through knowledge representation. \n",
    "\n",
    "5. Manifold Representations: Mapping the data from high dimension to low dimension can reveal hidden underlying structures within the data. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "REPRESENTATION_LEARNING.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
