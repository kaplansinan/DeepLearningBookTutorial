{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization in Deep Learning\n",
    "\n",
    "A common goal in deep learning and machine learning field is to generalize well on both training and test data (also new inputs). The common approach to tackle this problem is to reduce generalization(test error). As in  traditional machine learning models, there are many strategies to achieve this task. These strategies are known as **regularization** techniques which are  further explained in details below:\n",
    "* Parameter Norm Penalties\n",
    "    * $L^2$ Regularization\n",
    "    * $L^1$ Regularization\n",
    "* Dataset Augmentations\n",
    "* Noise Robustness\n",
    "* Semi-Supervised Learning\n",
    "* Multitask Learning\n",
    "* Early Stopping\n",
    "* Parameter typing and parameter sharing\n",
    "    * Transfer Learning\n",
    "* Sparse Representations\n",
    "* Bagging and Ensemble Methods\n",
    "* Droput\n",
    "* Batch Normalization\n",
    "* Adversarial Training\n",
    "\n",
    "Regularization refers to a set of different techniques that lower the complexity of a neural network model during training, and thus prevent the overfitting.\n",
    "\n",
    "$$\\color{orange}{D_{KL} (P \\| Q) = \\mathbb{E}_{x \\sim P} \\Big[ log \\ \\frac{P(x)}{Q(x)} \\Big] = \\mathbb{E}_{x \\sim P} [log \\ P(x) - log \\ Q(x)] \\tag{29}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Parameter Norm Penalties\n",
    "\n",
    "The main idea behind norm penalties is to limit the capacity of model by adding parameter norm penalty $\\color{blue}{\\Omega(\\Theta)}$ to the objective function $J$ given below.\n",
    "\n",
    "$$\\color{orange}{\\tilde{J}(\\Theta;X,y) = J(\\Theta;X,y) + \\alpha\\Omega(\\Theta)}$$\n",
    "\n",
    "where $\\alpha \\in [0,\\infty)$ is a hyperparameter that controls the contribution of norm penalty. Larger the value of $\\alpha$: the more reularization is applied to cost function w.r.t. a given model. \n",
    "\n",
    "$J$ is prone to result in different solutions w.r.t. choice of the parameter norm $\\Omega$. This section will be covering different choices of the parameter norm and how it affects the result. \n",
    "\n",
    "Note that in the context of neural networks, the norm penalty $\\Omega$ is only applied to weights of a network. The biases are not regularized as they are prone to introduce significant amount of underfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. $L^2$ Parameter Regulazrization\n",
    "\n",
    "This regularization type is known as **weight decay**. The regularization term added to objective function is defined as  $\\color{blue}{\\Omega(\\Theta) = \\frac{1}{2} \\lVert w\\rVert^2}$. \n",
    "\n",
    "Note that $L^2$ regularization is also known as **ridge regression** or **Tikhonov Regularization**. \n",
    "\n",
    "The objective function with weight decay is given below:\n",
    "\n",
    "$$\\color{orange}{\\tilde{J}(w;X,y) =  \\frac{\\alpha}{2}w^Tw + J(w;X,y)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. $L^1$ Parameter Regulazrization\n",
    "\n",
    "In addition to weight decay, there is another way to penalize the weights by adding $\\color{blue}{\\Omega(\\Theta) =  \\lVert w\\rVert_1}$. This is also called LASSO. This is the sum of absolute values of the invididual parameters. The objective function  with this type regularization takes the following shape. \n",
    "\n",
    "\n",
    "\n",
    "$$\\color{orange}{\\tilde{J}(w;X,y) =  \\alpha \\lVert w\\rVert_1 + J(w;X,y)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing L2 regularization encourages the weight values towards zero (but not exactly zero)\n",
    "Performing L1 regularization encourages the weight values to be zero\n",
    "\n",
    "The main difference between L1 and L2 regularization is that L1 can yield sparse models while L2 doesn't. Sparse model is a great property to have when dealing with high-dimensional data, for at least 2 reasons.\n",
    "\n",
    "Model compression: increasingly important due to the mobile growth\n",
    "Feature selection: it helps to know which features are important and which features are not or redundant.\n",
    "\n",
    "\n",
    "The L1 regularization zeroes out many per-features weights.\n",
    "\n",
    "The L2 regularization results in plenty of relatively small but nonzero ones.\n",
    "\n",
    "Thus, if reducing the feature space is important, there’s a compelling reason to pick the L1 one over the L2 one.\n",
    "\n",
    "Natural examples of where it could be valuable to reduce the feature space could be:\n",
    "\n",
    "when it’s important to maximize the QPS of applying the model,\n",
    "when it’s important to minimize the size of the data file with feature values which is staged to production, or\n",
    "when features are computed somewhat independently, and thus eliminating some of them makes [re-]cooking the training data set faster and/or cheaper.\n",
    "For most practical purposes, if in doubt, there’s a simple answer that can hardly be wrong: Try both L1 and L2, and see for yourself how well does the training generalize in either case for your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dataset Augmentations\n",
    "\n",
    "It is a well-known fact that deep learning models are data hungry. Therefore, it is crucial to have enough data to train a deep learning model for better accuracy. However, in rela life, this is usually not possible depending on the task such as medical imaging. One way to approachthis problem is to create fake data and add it to training set\n",
    "\n",
    "As the generation of fake data is not an easy taks due to the distirbution of data in real life, once might choose to augment the data for a specific task. Augmentation enables a model to become invariant to many features depending on the task at hand. For instance, in object detection tasks it is significant to make model rotation, translation and brightness invariant. To do so we can add augmentations to do so. This approach is covered in details in  notebook 5(DATA AUGMENTATION)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Injecting Noise to Output Targets\n",
    "Remember what happens when we train a network with hard targets? As we discussed above as well, the logit of the correct class is much larger than any of the incorrect logit. Not only this, the incorrect logits are very different from one other. Training a network with label smoothing helps to avoid these two problems. How?\n",
    "It encourages the difference between the logit of the correct class and the logits of incorrect classes to be a constant dependent on α.\n",
    "It encourages the activations of the penultimate layer to be close to the template of the correct class and equally distant to the templates of the incorrect classes.\n",
    "\n",
    "Considering possible mistakes in outpur targets($y$) of many datasets, there is a way to \n",
    "\n",
    "In essence, label smoothing will help your model to train around mislabeled data and consequently improve its robustness and performance. But what if your training data contains incorrect labeling? What if a dog was labeled as a cat? \n",
    "\n",
    "One way to solve this issues is to apply label-smoothing. **Label-smoothing** regularizes a model based on a softmax with $k$ output values by replacing the hard 0 and 1 classification targets with targets of $\\frac{\\epsilon}{k-1}$ and $1 - \\epsilon$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Semi-supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine you want to train a model to classify text documents but you want to give your algorithm a hint about how to construct the categories. You want to use only a very small portion of labeled text documents because every document is not labeled and at the same time you want your model to classify the unlabeled documents as accurately as possible based on the documents that are already labeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Multitask Learning\n",
    "\n",
    "[TODO]: rewrite it\n",
    "\n",
    "Multi tasking is defined as a way to improve generalization by pooling the examples from several tasks. The learning of multiple tasks enforces the network to learn good representations, thus increasing the generalization capability of the model. \n",
    "\n",
    "Since information sharing is the core of MTL, learning multiple tasks simultaneously reduces overfitting, even in presence of reduced datasets. Also, MTL is a special case of transfer learning (Pan and Yang, 2010), where (i) there is no distinction between tasks; and (ii) the objective is to increase performance for all the involved tasks.\n",
    "\n",
    "MTL allows having just one shared model instead of independent models per task. This helps reduce storage space, decreases training times and is easier to deploy and maintain The figure below illustrates the underlying assumption how the MTL work. The lower layers of a deep network (whether it\n",
    "is supervised and feedforward or includes a generative component with downward arrows)\n",
    "can be shared across such tasks, while task-specific parameters (associated respectively\n",
    "with the weights into and from h(1) and h(2)) can be learned on top of those yielding a\n",
    "shared representation h(shared). The underlying assumption is that there exists a common\n",
    "pool of factors that explain the variations in the input x, while each task is associated\n",
    "with a subset of these factors. In this example, it is additionally assumed that top-level\n",
    "hidden units h(1) and h(2) are specialized to each task (respectively predicting y(1) and\n",
    "y (2)) while some intermediate-level representation h(shared) is shared across all tasks. In\n",
    "the unsupervised learning context, it makes sense for some of the top-level factors to be\n",
    "associated with none of the output tasks (h(3)): these are the factors that explain some of\n",
    "the input variations but are not relevant for predicting y(1) or y(2) .\n",
    "\n",
    "<img src=\"fig/multi-task.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Early Stopping\n",
    "\n",
    "There is an option to regularize deep learning models by watching validation error. The procedure is as follows: each time when validation error improves we keep copy of the parameters at this stage. That enables us to return these parameters at the end of training rather than the latest parameters. The scheduled training for certain number of epochs is terminated when no parameters improved over the best recorded validation error for some pre-specific number of iterations. This strategy is known as **early stopping**. The algorithm below is an illustration of the aforementioned algorithm. \n",
    "\n",
    "<img src=\"fig/early_stopping.png\" width=500 height=500 />\n",
    "Early stopping requires to have an extra set for validation instead of having only training data during the training procedure. In practical applications of deep learning, early stopping is used quite often as part of training scheduling. \n",
    "\n",
    "Consider the figure given below to understand why early stopping works. After each epoch, the model learns the data and updates the weights accordingly. Training and validation error decreases as long as our model is generalising the input data. After some iterations, the model starts to memorize the data and even though training error decreases the validation error increases, causing the overfitting of the model.\n",
    "\n",
    "If the performance of the model on the validation dataset starts to degrade (e.g. loss begins to increase, or accuracy begins to decrease), then the training process is stopped. The model at this stage have low variance and is known to generalize the data well. Training the model further would increase the variance of the model and lead to overfitting. \n",
    "\n",
    "<img src=\"fig/early_stopping_2.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Parameter Sharing\n",
    "\n",
    "This technique enables previously learnt parameters on same problem domain to be tranferred to another problem in the same domain such as image classification. The approach in known as Transfer Learning and it is covered further in details in notebook 6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Bagging and Ensemble Methods\n",
    "[TODO] rewrite explanation\n",
    "\n",
    "Bagging (short for bootstrap aggregating) is a technique for reducing generalization error by combining several models. The idea is to train several different models separately, then have all of the models vote on the output for test examples. This is an example of a general strategy in machine learning called model averaging. Techniques employing this strategy are known\n",
    "as ensemble methods\n",
    "\n",
    "\n",
    "Another way to think about Ensemble learning is **Fable of blind men and elephant**. All of the blind men had their own description of the elephant. Even though each of the description was true, it would have been better to come together and discuss their undertanding before coming to final conclusion. This story perfectly describes the Ensemble learning method.\n",
    "<img src=\"fig/ensemble_story.jpeg\" width=500 height=500 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blind men are essentially machine-learning models trying to understand the manifold of the training data, each from its own perspective, using its own assumptions\n",
    "(provided by the unique architecture of the model and the unique random weight initialization). Each of them gets part of the truth of the data, but not the whole truth. By\n",
    "pooling their perspectives together, you can get a far more accurate description of the\n",
    "data. The elephant is a combination of parts: not any single blind man gets it quite\n",
    "right, but, interviewed together, they can tell a fairly accurate story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to pool the predictions of a set of classifiers (to ensemble the classifiers) is to average their predictions at inference time:\n",
    "<img src=\"fig/ensemble.png\" width=700 height=200 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will work only if the classifiers are more or less equally good. If one of them is significantly worse than the others, the final predictions may not be as good as the best\n",
    "classifier of the group.\n",
    "A smarter way to ensemble classifiers is to do a weighted average, where the\n",
    "weights are learned on the validation data—typically, the better classifiers are given a\n",
    "higher weight, and the worse classifiers are given a lower weight. To search for a good\n",
    "set of ensembling weights, you can use random search or a simple optimization algorithm such as Nelder-Mead:\n",
    "\n",
    "\n",
    "<img src=\"fig/ensemble_2.png\" width=700 height=200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Dropout\n",
    "dropout refers to ignoring units (i.e. neurons) during the training phase of certain set of neurons which is chosen at random. By “ignoring”, I mean these units are not considered during a particular forward or backward pass.\n",
    "More technically, At each training stage, individual nodes are either dropped out of the net with probability $1-p$ or kept with probability $p$, so that a reduced network is left; incoming and outgoing edges to a dropped-out node are also removed.\n",
    "<img src=\"fig/dropout.gif\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit",
   "language": "python",
   "name": "python361064bit44046df9ee9f4b6794be314555d2632c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
